{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b742a94",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92bdacf",
   "metadata": {},
   "source": [
    "In this notebook, we look at how the various different pieces of the Hylode architecture come together to ease the ML4H model development/deployment process.\n",
    "\n",
    "In `vignette_1_training_set`, we looked at how HyCastle and the lens abstraction make for consistent training pathways between model development and deployment. \n",
    "\n",
    "Here, we bring these components together in a modelling workflow. Core steps are to show:\n",
    "\n",
    "    ~ how HyCastle and the lens come together to make our training & validation sets\n",
    "    ~ how we use MLFlow as a central spine for recording our model training\n",
    "    ~ how we then can check out models from MLFlow - either for further evaluation or live deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481f556",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c43c90",
   "metadata": {},
   "source": [
    "We start with a long list of imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf5511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:16:27.480223Z",
     "iopub.status.busy": "2021-12-01T17:16:27.480077Z",
     "iopub.status.idle": "2021-12-01T17:16:33.556720Z",
     "shell.execute_reply": "2021-12-01T17:16:33.556546Z",
     "shell.execute_reply.started": "2021-12-01T17:16:27.480158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from uuid import uuid4\n",
    "import datetime\n",
    "\n",
    "import cloudpickle\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, log_loss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.pipeline import Pipeline as SKPipeline\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c229073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:16:33.557025Z",
     "iopub.status.busy": "2021-12-01T17:16:33.556927Z",
     "iopub.status.idle": "2021-12-01T17:16:46.811634Z",
     "shell.execute_reply": "2021-12-01T17:16:46.811461Z",
     "shell.execute_reply.started": "2021-12-01T17:16:33.556969Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hylib.dt import LONDON_TZ\n",
    "from hycastle.lens.base import BaseLens\n",
    "from hycastle.lens.transformers import DateTimeExploder, timedelta_as_hours\n",
    "from hycastle.lens.icu import BournvilleICUSitRepLens\n",
    "from hycastle.icu_store.live import live_dataset\n",
    "from hycastle.icu_store.retro import retro_dataset\n",
    "from hymind.lib.models.icu_aggregate import AggregateDemandModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d168a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:16:46.812001Z",
     "iopub.status.busy": "2021-12-01T17:16:46.811889Z",
     "iopub.status.idle": "2021-12-01T17:16:46.813518Z",
     "shell.execute_reply": "2021-12-01T17:16:46.813358Z",
     "shell.execute_reply.started": "2021-12-01T17:16:46.811942Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialise MLFlow\n",
    "mlflow_var = os.getenv('HYMIND_REPO_TRACKING_URI')\n",
    "mlflow.set_tracking_uri(mlflow_var)   \n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3984710a",
   "metadata": {},
   "source": [
    "# Training & Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb4e14",
   "metadata": {},
   "source": [
    "Okay. So as our first port of call, we want to show how HyCastle and the lens abstraction can furnish training and validation sets for our modelling efforts. \n",
    "\n",
    "To recap, we start here with the `retro_dataset` function from HyCastle. \n",
    "\n",
    "We pass the argument 'T03' to restrict the patients we look at to the T03 ICU at UCLH. Because of the way Hylode has been configured for the ICU, this then gives one set of features (a row) per hour for every patient in our retrospective dataset. \n",
    "    \n",
    "Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa487e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:16:46.813812Z",
     "iopub.status.busy": "2021-12-01T17:16:46.813673Z",
     "iopub.status.idle": "2021-12-01T17:17:39.337752Z",
     "shell.execute_reply": "2021-12-01T17:17:39.337484Z",
     "shell.execute_reply.started": "2021-12-01T17:16:46.813722Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = retro_dataset('T03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5d56d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:39.338136Z",
     "iopub.status.busy": "2021-12-01T17:17:39.338010Z",
     "iopub.status.idle": "2021-12-01T17:17:39.342341Z",
     "shell.execute_reply": "2021-12-01T17:17:39.342220Z",
     "shell.execute_reply.started": "2021-12-01T17:17:39.338068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8456d79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:39.342620Z",
     "iopub.status.busy": "2021-12-01T17:17:39.342514Z",
     "iopub.status.idle": "2021-12-01T17:17:39.422944Z",
     "shell.execute_reply": "2021-12-01T17:17:39.422825Z",
     "shell.execute_reply.started": "2021-12-01T17:17:39.342560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce581318",
   "metadata": {},
   "source": [
    "Let's check to see the date range that `retro_dataset` covers. (n.b. `horizon_dt` is the datetime for the particular hourly snapshot of a patient's features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40aae74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:39.423213Z",
     "iopub.status.busy": "2021-12-01T17:17:39.423106Z",
     "iopub.status.idle": "2021-12-01T17:17:39.426848Z",
     "shell.execute_reply": "2021-12-01T17:17:39.426719Z",
     "shell.execute_reply.started": "2021-12-01T17:17:39.423150Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.horizon_dt.min(), df.horizon_dt.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d94a3b",
   "metadata": {},
   "source": [
    "Okay. So we see that the retrospective data currently in Hylode runs from c. April '21. For the sake of this demo, let's take April, May & June as our training data. And then July for validation.\n",
    "\n",
    "We define some corresponding datetimes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59995941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:39.427098Z",
     "iopub.status.busy": "2021-12-01T17:17:39.427003Z",
     "iopub.status.idle": "2021-12-01T17:17:39.430410Z",
     "shell.execute_reply": "2021-12-01T17:17:39.430287Z",
     "shell.execute_reply.started": "2021-12-01T17:17:39.427042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_train_dt = datetime.datetime(2021,4,3,2,0,0).astimezone(LONDON_TZ)\n",
    "end_train_dt = datetime.datetime(2021,6,30,23,0,0).astimezone(LONDON_TZ)\n",
    "\n",
    "start_valid_dt = datetime.datetime(2021,7,1,1,0,0).astimezone(LONDON_TZ)\n",
    "end_valid_dt = datetime.datetime(2021,7,31,23,0,0).astimezone(LONDON_TZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebc355",
   "metadata": {},
   "source": [
    "Using these date ranges, we take slices of the `retro_dataset` corresponding to our training and validation windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd7631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:39.430651Z",
     "iopub.status.busy": "2021-12-01T17:17:39.430564Z",
     "iopub.status.idle": "2021-12-01T17:17:39.494207Z",
     "shell.execute_reply": "2021-12-01T17:17:39.494020Z",
     "shell.execute_reply.started": "2021-12-01T17:17:39.430595Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df[(start_train_dt < df['horizon_dt']) & (df['horizon_dt'] < end_train_dt)]\n",
    "valid_df = df[(start_valid_dt < df['horizon_dt']) & (df['horizon_dt'] < end_valid_dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cf893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:39.494506Z",
     "iopub.status.busy": "2021-12-01T17:17:39.494395Z",
     "iopub.status.idle": "2021-12-01T17:17:39.560488Z",
     "shell.execute_reply": "2021-12-01T17:17:39.560350Z",
     "shell.execute_reply.started": "2021-12-01T17:17:39.494444Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2f474",
   "metadata": {},
   "source": [
    "This is a start, as we now have the appropriate time restrictions for a basic experimental setup -- although you will notice that our `train_df` still has the full set of output features from HyCastle. As per our demonstration of the `lens` in the previous notebook, we want to restrict the set of features we see and pre-process them appropriately.\n",
    "\n",
    "We start by defining a lens as below... (If this still looks a bit daunting, the appendix in the previous notebook on inspecting the different components of the lens might come in useful.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc356c17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:39.561135Z",
     "iopub.status.busy": "2021-12-01T17:17:39.560705Z",
     "iopub.status.idle": "2021-12-01T17:17:39.564663Z",
     "shell.execute_reply": "2021-12-01T17:17:39.564526Z",
     "shell.execute_reply.started": "2021-12-01T17:17:39.560740Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DemoLens(BaseLens):\n",
    "    numeric_output = True\n",
    "    index_col = \"episode_slice_id\"\n",
    "\n",
    "    @property\n",
    "    def input_cols(self) -> List[str]:\n",
    "        return [\n",
    "            \"episode_slice_id\",\n",
    "            \"admission_age_years\",\n",
    "            \"avg_heart_rate_1_24h\",\n",
    "            \"max_temp_1_12h\",\n",
    "            \"avg_resp_rate_1_24h\",\n",
    "            \"elapsed_los_td\",\n",
    "            \"admission_dt\",\n",
    "            \"horizon_dt\",\n",
    "            \"n_inotropes_1_4h\",\n",
    "            \"wim_1\",\n",
    "            \"bay_type\",\n",
    "            \"sex\",\n",
    "            \"vent_type_1_4h\",\n",
    "        ]\n",
    "\n",
    "    def specify(self) -> ColumnTransformer:\n",
    "        return ColumnTransformer(\n",
    "            [\n",
    "                (\n",
    "                    \"select\",\n",
    "                    \"passthrough\",\n",
    "                    [\n",
    "                        \"episode_slice_id\",\n",
    "                        \"admission_age_years\",\n",
    "                        \"n_inotropes_1_4h\",\n",
    "                        \"wim_1\",\n",
    "                    ],\n",
    "                ),\n",
    "                (\"bay_type_enc\", OneHotEncoder(), [\"bay_type\"]),\n",
    "                (\n",
    "                    \"sex_enc\",\n",
    "                    OrdinalEncoder(\n",
    "                        handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    "                    ),\n",
    "                    [\"sex\"],\n",
    "                ),\n",
    "                (\n",
    "                    \"admission_dt_exp\",\n",
    "                    DateTimeExploder(),\n",
    "                    [\"admission_dt\", \"horizon_dt\"],\n",
    "                ),\n",
    "                (\n",
    "                    \"vent_type_1_4h_enc\",\n",
    "                    OrdinalEncoder(\n",
    "                        handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    "                    ),\n",
    "                    [\"vent_type_1_4h\"],\n",
    "                ),\n",
    "                (\n",
    "                    \"vitals_impute\",\n",
    "                    SimpleImputer(strategy=\"mean\", add_indicator=False),\n",
    "                    [\n",
    "                        \"avg_heart_rate_1_24h\",\n",
    "                        \"max_temp_1_12h\",\n",
    "                        \"avg_resp_rate_1_24h\",\n",
    "                    ],\n",
    "                ),\n",
    "                # note we include then elapsed length of stay as a feature for our model,\n",
    "                # as an alternative to training multiple models for different timepoints\n",
    "                (\n",
    "                    \"elapsed_los_td_hrs\",\n",
    "                    FunctionTransformer(timedelta_as_hours),\n",
    "                    [\"elapsed_los_td\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babcb20a",
   "metadata": {},
   "source": [
    "So what we want to do is apply this lens to `train_df` and `valid_df` to give us our feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1c79d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:39.564954Z",
     "iopub.status.busy": "2021-12-01T17:17:39.564847Z",
     "iopub.status.idle": "2021-12-01T17:17:40.923368Z",
     "shell.execute_reply": "2021-12-01T17:17:40.923205Z",
     "shell.execute_reply.started": "2021-12-01T17:17:39.564883Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we start be instantiating the lens\n",
    "lens = DemoLens()\n",
    "\n",
    "# then we fit the lens on the training set, and transform that df\n",
    "X_train = lens.fit_transform(train_df)\n",
    "\n",
    "# similarly for the validation set, although here we only use transform(),\n",
    "# as we have already fit the lens on train_df\n",
    "X_valid = lens.transform(valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6836434",
   "metadata": {},
   "source": [
    "The `ICU Demand` pipeline also usefully includes our predictive label of whether or not the patient was discharged within 48 hours of the `horizon_df`. We use this to define our targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14df8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:40.923674Z",
     "iopub.status.busy": "2021-12-01T17:17:40.923579Z",
     "iopub.status.idle": "2021-12-01T17:17:40.926116Z",
     "shell.execute_reply": "2021-12-01T17:17:40.925996Z",
     "shell.execute_reply.started": "2021-12-01T17:17:40.923617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = train_df['discharged_in_48hr'].astype(int)\n",
    "y_valid = valid_df['discharged_in_48hr'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560513a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:40.926492Z",
     "iopub.status.busy": "2021-12-01T17:17:40.926350Z",
     "iopub.status.idle": "2021-12-01T17:17:40.932174Z",
     "shell.execute_reply": "2021-12-01T17:17:40.932057Z",
     "shell.execute_reply.started": "2021-12-01T17:17:40.926416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e907ce",
   "metadata": {},
   "source": [
    "To check that the lens has made our features and labels look the way our SKLearn model wants them to look, let's pass them through a dummy Random Forest run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e6bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:40.932468Z",
     "iopub.status.busy": "2021-12-01T17:17:40.932367Z",
     "iopub.status.idle": "2021-12-01T17:17:42.227607Z",
     "shell.execute_reply": "2021-12-01T17:17:42.227481Z",
     "shell.execute_reply.started": "2021-12-01T17:17:40.932412Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = RandomForestClassifier(n_jobs=-1)\n",
    "%time m.fit(X_train.values, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a7d29",
   "metadata": {},
   "source": [
    "Great! So with that our training and validation sets are ready to start running experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144b06b",
   "metadata": {},
   "source": [
    "# MLFlow Training Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f184b9",
   "metadata": {},
   "source": [
    "In Hylode modelling work to date, a central part of the workflow has been an open source software product from Databricks called MLFlow. Why have we felt the need to incorporate this into our stack?\n",
    "\n",
    "Even working on an individual level, rigour around logging experimental results and outcomes yield a strong dividend. MLFlow provides a very flexible framework for achieving this - whether one is simply looking to keep house or aiming higher, perhaps at easy reproduction of results.\n",
    "\n",
    "In the Hylode scenario, where we are looking at collaboration between multiple different team members - both data scientists and software developers - the return from using a tool like MLFlow is an order of magnitude greater still. By centralising our models and data on performance, MLFlow eases the handover of models trained by the HyMind team into models deployed by the HySys team.\n",
    "\n",
    "Excellent MLFlow documentation can be found [here](https://www.mlflow.org/docs/latest/index.html). \n",
    "\n",
    "Here our aims are modest. We just want to log a simple modelling workflow for ICU discharge. Key elements to look out for are:\n",
    "\n",
    "    ~ the entire experiment logged against a single experiment ID\n",
    "    ~ metadata about training and validation sets logged consistently in MLFlow\n",
    "    ~ all metrics (accuracy etc.) logged from each training run on MLFlow\n",
    "    ~ the actual model file for each training run stored in MLFlow (from where it's easy for the HySys team to check it out)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851fd3b",
   "metadata": {},
   "source": [
    "As a first step let's create a new experiment. We use the pipe-separated `(Owner|Type|Name|Date)` naming convention to keep each other's work from getting mixed up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad11a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:42.227863Z",
     "iopub.status.busy": "2021-12-01T17:17:42.227760Z",
     "iopub.status.idle": "2021-12-01T17:17:42.423571Z",
     "shell.execute_reply": "2021-12-01T17:17:42.423436Z",
     "shell.execute_reply.started": "2021-12-01T17:17:42.227805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Owner|Type|Name|Date e.g. 'TK|models|vignette|2021-11-22'\n",
    "# n.b. if experiment name already exists, this cell with throw an error\n",
    "#\n",
    "# => add a unique experiment below <=\n",
    "exp_name =\n",
    "\n",
    "\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = exp_name\n",
    "experiment_id = mlflow.create_experiment(exp_name)\n",
    "\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d509893",
   "metadata": {},
   "source": [
    "With this done, you should see a new experiment exists on the bottom left hand side of the MLFlow web user interface (which we refer to as the HyMind Repo). As of the time of writing, the HyMind Repo can be accessed [here](http://uclvlddpragae08:5008/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e5ba81",
   "metadata": {},
   "source": [
    "Now. What we want to do as we move along the modelling pathway is to log the salient bits of information in MLFlow as we go. To make this easier to do, we start by defining a few convenience functions to log strings, dicts and lenses.\n",
    "\n",
    "n.b. these all rely on `mlflow.log_artifact()` which takes a file from our local directory and adds it to the HyMind Repo. (Alongside our import statements above, we let MLFlow where our Repo is using the `HYMIND_REPO_TRACKING_URI` environment variable.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36eb4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:42.424342Z",
     "iopub.status.busy": "2021-12-01T17:17:42.423738Z",
     "iopub.status.idle": "2021-12-01T17:17:42.427072Z",
     "shell.execute_reply": "2021-12-01T17:17:42.426948Z",
     "shell.execute_reply.started": "2021-12-01T17:17:42.423779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_path = Path('tmp')\n",
    "tmp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def mlflow_log_string(text, filename):\n",
    "    full_path = tmp_path / filename\n",
    "    with open(full_path, 'w') as f:\n",
    "        f.write(str(text))\n",
    "    mlflow.log_artifact(full_path)\n",
    "\n",
    "def mlflow_log_tag_dict(tag_dict, filename):\n",
    "    \"\"\"Logs tag dict to MLflow (while preserving order unlike mlflow.log_dict)\"\"\"\n",
    "    full_path = tmp_path / filename\n",
    "    with open(full_path, 'w') as f:\n",
    "        yaml.dump(tag_dict, f, sort_keys=False)\n",
    "    mlflow.log_artifact(full_path)\n",
    "    \n",
    "def mlflow_log_lens(l):\n",
    "    full_path = l.pickle(tmp_path)\n",
    "    mlflow.log_artifact(full_path, 'lens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14df33",
   "metadata": {},
   "source": [
    "First off, to get a hang of this, let's run a test of sending some data to MLFlow. Let's try storing the start and end time for our trainging and validation runs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2247d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:42.427327Z",
     "iopub.status.busy": "2021-12-01T17:17:42.427230Z",
     "iopub.status.idle": "2021-12-01T17:17:42.432363Z",
     "shell.execute_reply": "2021-12-01T17:17:42.432219Z",
     "shell.execute_reply.started": "2021-12-01T17:17:42.427272Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag_dict = {\n",
    "    'start_train_dt': start_train_dt,\n",
    "    'end_train_dt': end_train_dt,    \n",
    "    'start_valid_dt': start_valid_dt,\n",
    "    'end_valid_dt': end_valid_dt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124553e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:42.432644Z",
     "iopub.status.busy": "2021-12-01T17:17:42.432538Z",
     "iopub.status.idle": "2021-12-01T17:17:43.462420Z",
     "shell.execute_reply": "2021-12-01T17:17:43.460140Z",
     "shell.execute_reply.started": "2021-12-01T17:17:42.432585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow_log_tag_dict(tag_dict, 'tag_dict.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7caf72",
   "metadata": {},
   "source": [
    "Now, if you navigate back to the HyMind Repo MLFlow UI and click on the new experiment that you created (on the bottom left hand side), you should now see that there is a recent row in the table that lists runs for this experiment.\n",
    "\n",
    "If you then click on this run, you can scroll down the page and under 'Artifacts' you will find a copy of `tag_dict.yaml`. This is now stored in the HyMind Repo to pull out as and when we need.\n",
    "\n",
    "One point worth mentioning the `with mlflow.start_run()` syntax above, this is the standard MLFlow way to create a new run (nested under the current experiment). The `with` statement automatically closes the run at the end of the indented code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec7117",
   "metadata": {},
   "source": [
    "## A fuller example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00597c9c",
   "metadata": {},
   "source": [
    "With slightly better sense of how MLFlow works, we now turn to a fuller exemplar workflow. The example we look at here is running a simple parameter grid search for a Random Forest model of ICU discharge at 48 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1706ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:43.996267Z",
     "iopub.status.busy": "2021-12-01T17:17:43.996111Z",
     "iopub.status.idle": "2021-12-01T17:17:43.997838Z",
     "shell.execute_reply": "2021-12-01T17:17:43.997692Z",
     "shell.execute_reply.started": "2021-12-01T17:17:43.996206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the two most influential parameters \n",
    "# cf. https://scikit-learn.org/stable/modules/ensemble.html#parameters\n",
    "grid = {\n",
    "    'n_estimators':[10, 50, 100],\n",
    "    'max_features':[None, \"sqrt\", \"log2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321cf025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:17:45.400830Z",
     "iopub.status.busy": "2021-12-01T17:17:45.400667Z",
     "iopub.status.idle": "2021-12-01T17:19:08.936713Z",
     "shell.execute_reply": "2021-12-01T17:19:08.936394Z",
     "shell.execute_reply.started": "2021-12-01T17:17:45.400758Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# as the outcome of each training run (even with the same parameters) is non-deterministic,\n",
    "# we run two training runs per parameter combination.\n",
    "runs_per_param_set = 2\n",
    "\n",
    "for i in range(runs_per_param_set):\n",
    "    \n",
    "    for g in ParameterGrid(grid):\n",
    "        m = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            \n",
    "            # logging the tag dictionary, the run_type\n",
    "            mlflow_log_tag_dict(tag_dict, 'tag_dict.yaml')\n",
    "            mlflow.set_tag(\"run_type\", \"training\")\n",
    "            \n",
    "            # set and log this run's set of model parameters\n",
    "            m.set_params(**g)\n",
    "            mlflow.log_params(g)\n",
    "\n",
    "            m.fit(X_train.values, y_train.values.ravel())\n",
    "            \n",
    "            # calculate and log training and validation set accuracy\n",
    "            train_accuracy = m.score(X_train.values, y_train.to_numpy())\n",
    "            mlflow.log_metric('train_accuracy', train_accuracy)\n",
    "            valid_accuracy = m.score(X_valid.values, y_valid.to_numpy())       \n",
    "            mlflow.log_metric('valid_accuracy', valid_accuracy)\n",
    "            \n",
    "            # ditto for confusion matrices\n",
    "            train_confusion = confusion_matrix(m.predict(X_train.values), y_train.to_numpy())\n",
    "            mlflow_log_string(train_confusion, 'train_confusion.txt')\n",
    "            valid_confusion = confusion_matrix(m.predict(X_valid.values), y_valid.to_numpy())\n",
    "            mlflow_log_string(valid_confusion, 'valid_confusion.txt')\n",
    "\n",
    "            # store the trained SKLearn model, so we can check it out later\n",
    "            mlflow.sklearn.log_model(m, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf07cf",
   "metadata": {},
   "source": [
    "After this cells runs (which takes a minute or two), if you now return to the MLFlow UI, you will see that the experiment you created is now populated with a whole list of runs, one for each parameter set above. Clicking down into the run you will see all the attributes above have been stored (the tag dictionary, the parameters, the metrics, the model etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da9838",
   "metadata": {},
   "source": [
    "As a next step, we might want to pick out the model parameters that seem to have performed best - so we can then use these for further evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021899b",
   "metadata": {},
   "source": [
    "These runs can also be straightforwardly access from a notebook using `mlflow.search_runs()`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf63c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:08.937132Z",
     "iopub.status.busy": "2021-12-01T17:19:08.937013Z",
     "iopub.status.idle": "2021-12-01T17:19:09.209790Z",
     "shell.execute_reply": "2021-12-01T17:19:09.208450Z",
     "shell.execute_reply.started": "2021-12-01T17:19:08.937067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs()\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad50e6",
   "metadata": {},
   "source": [
    "From which starting point, it's simple to mark out the parameter set with the best mean validation accuracy, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf55acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:09.212860Z",
     "iopub.status.busy": "2021-12-01T17:19:09.211680Z",
     "iopub.status.idle": "2021-12-01T17:19:09.319620Z",
     "shell.execute_reply": "2021-12-01T17:19:09.318340Z",
     "shell.execute_reply.started": "2021-12-01T17:19:09.21226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = [col for col in runs if col.startswith('params')]\n",
    "best_params = runs.groupby(params)['metrics.valid_accuracy'].mean().idxmax()\n",
    "best_row = runs.set_index(keys=params).loc[best_params]\n",
    "\n",
    "best_run_id = list(best_row['run_id'])[0]\n",
    "best_run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd55fb",
   "metadata": {},
   "source": [
    "And then we can tag this as the best run from our training loop - and also log the lens we used to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f949f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:09.322310Z",
     "iopub.status.busy": "2021-12-01T17:19:09.321300Z",
     "iopub.status.idle": "2021-12-01T17:19:16.538908Z",
     "shell.execute_reply": "2021-12-01T17:19:16.538665Z",
     "shell.execute_reply.started": "2021-12-01T17:19:09.32175Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id=best_run_id):\n",
    "    # tag the run as best_row\n",
    "    mlflow.set_tag('best_run', 1)   \n",
    "\n",
    "    # log the lens\n",
    "    mlflow_log_lens(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530fd34",
   "metadata": {},
   "source": [
    "In the same breath, MLFlow gives us the option to register our model, which makes it easy to access and work with going forward - so let's do that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda074e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:16.539253Z",
     "iopub.status.busy": "2021-12-01T17:19:16.539121Z",
     "iopub.status.idle": "2021-12-01T17:19:16.540215Z",
     "shell.execute_reply": "2021-12-01T17:19:16.540071Z",
     "shell.execute_reply.started": "2021-12-01T17:19:16.539189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# => add a unique model name below <=\n",
    "# e.g. tk-random_forest-demo\n",
    "model_name ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ee1b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:16.540478Z",
     "iopub.status.busy": "2021-12-01T17:19:16.540366Z",
     "iopub.status.idle": "2021-12-01T17:19:16.675968Z",
     "shell.execute_reply": "2021-12-01T17:19:16.675825Z",
     "shell.execute_reply.started": "2021-12-01T17:19:16.540409Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n.b. each time you run this cell with the same model_name, the model version will increase by one\n",
    "registered_model = mlflow.register_model(f'runs:/{best_run_id}/model', model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab5a87",
   "metadata": {},
   "source": [
    "Which is great. And now you should be able to navigate to the MLFlow UI - and if you click on the 'Models' tab at the top of the page you should see your newly registered model waiting there on the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9f43f",
   "metadata": {},
   "source": [
    "# Checking models out from MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57966fb",
   "metadata": {},
   "source": [
    "By this stage of the notebook, we have invested quite a lot of effort in creating a parallel record of our experiment in MLFlow. In the final section of the notebook, we seek to show how this investment pays off. We work through two principal workflows:\n",
    "    \n",
    "    ~ checking out the model for forward pass prediction\n",
    "    ~ checking it out for further evaluation\n",
    "    \n",
    "But let's start simple by retrieving the model. First, a couple of simple methods that allow us to pull out info about the model we have just saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3ed87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:16.676333Z",
     "iopub.status.busy": "2021-12-01T17:19:16.676208Z",
     "iopub.status.idle": "2021-12-01T17:19:16.688324Z",
     "shell.execute_reply": "2021-12-01T17:19:16.688182Z",
     "shell.execute_reply.started": "2021-12-01T17:19:16.676275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first off, we can surface basic info about the model using our model_name and version.\n",
    "\n",
    "model_info = client.get_model_version(model_name, registered_model.version)\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bcba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:16.688592Z",
     "iopub.status.busy": "2021-12-01T17:19:16.688487Z",
     "iopub.status.idle": "2021-12-01T17:19:16.706533Z",
     "shell.execute_reply": "2021-12-01T17:19:16.706408Z",
     "shell.execute_reply.started": "2021-12-01T17:19:16.688536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can then go deeper and inspect the run itself\n",
    "run_info = client.get_run(model_info.run_id)\n",
    "run_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf41b8",
   "metadata": {},
   "source": [
    "Happy that the information above looks about right, we can now use the `model_name` and `version` to load our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5241d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:16.706822Z",
     "iopub.status.busy": "2021-12-01T17:19:16.706706Z",
     "iopub.status.idle": "2021-12-01T17:19:16.976217Z",
     "shell.execute_reply": "2021-12-01T17:19:16.976086Z",
     "shell.execute_reply.started": "2021-12-01T17:19:16.706755Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = mlflow.sklearn.load_model(f'models:/{model_name}/{registered_model.version}')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4e350",
   "metadata": {},
   "source": [
    "Moreover, using `model_info.run_id`, we can also reload the lens we used to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626fbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:16.976498Z",
     "iopub.status.busy": "2021-12-01T17:19:16.976390Z",
     "iopub.status.idle": "2021-12-01T17:19:23.576210Z",
     "shell.execute_reply": "2021-12-01T17:19:23.576062Z",
     "shell.execute_reply.started": "2021-12-01T17:19:16.976440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    tmp_dir = Path(tmp)\n",
    "    \n",
    "    client.download_artifacts(model_info.run_id, 'lens', tmp_dir)\n",
    "    \n",
    "    lens_path = next((tmp_dir / 'lens').rglob('*.pkl'))\n",
    "    with open(lens_path, 'rb') as f:\n",
    "        loaded_lens = pickle.load(f)\n",
    "        \n",
    "loaded_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56646de",
   "metadata": {},
   "source": [
    "## Forward pass prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7ee7f",
   "metadata": {},
   "source": [
    "With the model and the lens loaded, the `live_dataset` from HyCastle makes it extremely straightforward to run the forward pass. (n.b. reusing the identical components to in our retrospective training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a7daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:23.576512Z",
     "iopub.status.busy": "2021-12-01T17:19:23.576399Z",
     "iopub.status.idle": "2021-12-01T17:19:23.629969Z",
     "shell.execute_reply": "2021-12-01T17:19:23.629842Z",
     "shell.execute_reply.started": "2021-12-01T17:19:23.576447Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "live_df = live_dataset('T03')\n",
    "live_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc488fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:23.630229Z",
     "iopub.status.busy": "2021-12-01T17:19:23.630131Z",
     "iopub.status.idle": "2021-12-01T17:19:23.643723Z",
     "shell.execute_reply": "2021-12-01T17:19:23.643581Z",
     "shell.execute_reply.started": "2021-12-01T17:19:23.630174Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# and inspecting the dataframe, note the most recent admission_dt\n",
    "live_df.loc[:, ['episode_slice_id', 'admission_dt', 'bed_code', 'avg_heart_rate_1_24h']].sort_values('admission_dt', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0794c8",
   "metadata": {},
   "source": [
    "Now let's try to run some patient-level predictions based on our saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f121cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:23.644016Z",
     "iopub.status.busy": "2021-12-01T17:19:23.643910Z",
     "iopub.status.idle": "2021-12-01T17:19:23.683345Z",
     "shell.execute_reply": "2021-12-01T17:19:23.683204Z",
     "shell.execute_reply.started": "2021-12-01T17:19:23.643956Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first we transform the live_df with our loaded_lens\n",
    "X_df = loaded_lens.transform(live_df)\n",
    "X_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b774d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:23.683642Z",
     "iopub.status.busy": "2021-12-01T17:19:23.683531Z",
     "iopub.status.idle": "2021-12-01T17:19:23.718921Z",
     "shell.execute_reply": "2021-12-01T17:19:23.718792Z",
     "shell.execute_reply.started": "2021-12-01T17:19:23.683580Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# making the predictions\n",
    "predictions = model.predict_proba(X_df.values)\n",
    "\n",
    "# adding the predictions to our live_df dataframe\n",
    "live_df['prediction'] = predictions[:, 1]\n",
    "live_df.loc[:, ['episode_slice_id', 'prediction']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b5e330",
   "metadata": {},
   "source": [
    "We can even then get a sense of how this segues into the aggregate prediction problem, using the `AggregateDemandModel` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a67d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T08:01:17.522270Z",
     "iopub.status.busy": "2021-11-22T08:01:17.522133Z",
     "iopub.status.idle": "2021-11-22T08:01:17.529894Z",
     "shell.execute_reply": "2021-11-22T08:01:17.529716Z",
     "shell.execute_reply.started": "2021-11-22T08:01:17.522211Z"
    }
   },
   "outputs": [],
   "source": [
    "AggregateDemandModel??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168ed3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:23.719208Z",
     "iopub.status.busy": "2021-12-01T17:19:23.719097Z",
     "iopub.status.idle": "2021-12-01T17:19:24.638101Z",
     "shell.execute_reply": "2021-12-01T17:19:24.637964Z",
     "shell.execute_reply.started": "2021-12-01T17:19:23.719149Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_demand = AggregateDemandModel()\n",
    "agg_predictions = agg_demand.predict(context=\"\", \n",
    "                                     model_input=live_df.loc[:, ['prediction']].rename(mapper={'prediction':'prediction_as_real'},axis=1))\n",
    "agg_predictions.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42720eb0",
   "metadata": {},
   "source": [
    "## Further evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e38d27",
   "metadata": {},
   "source": [
    "Another use case would be that having done our initial training, we still have plenty of work to do evaluating it's performance. We give a very simple outline here of what that might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be4991",
   "metadata": {},
   "source": [
    "We start by putting our two loaded components from MLFlow: `loaded_tag_dict` and `loaded_lens` together to rebuild our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb205b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:24.638382Z",
     "iopub.status.busy": "2021-12-01T17:19:24.638281Z",
     "iopub.status.idle": "2021-12-01T17:19:25.448535Z",
     "shell.execute_reply": "2021-12-01T17:19:25.448403Z",
     "shell.execute_reply.started": "2021-12-01T17:19:24.638326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    tmp_dir = Path(tmp)\n",
    "    \n",
    "    client.download_artifacts(model_info.run_id, './', tmp_dir)\n",
    "    \n",
    "    tag_dict_path = tmp_dir / 'tag_dict.yaml'\n",
    "    with open(tag_dict_path, 'r') as stream:\n",
    "        loaded_tag_dict = yaml.load(stream, Loader=yaml.FullLoader)\n",
    "        \n",
    "loaded_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49824aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:25.448860Z",
     "iopub.status.busy": "2021-12-01T17:19:25.448726Z",
     "iopub.status.idle": "2021-12-01T17:19:25.480668Z",
     "shell.execute_reply": "2021-12-01T17:19:25.480483Z",
     "shell.execute_reply.started": "2021-12-01T17:19:25.448800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_valid_df = df[(loaded_tag_dict['start_valid_dt'] < df['horizon_dt']) &\n",
    "                 (df['horizon_dt'] < loaded_tag_dict['end_valid_dt'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8264cab9",
   "metadata": {},
   "source": [
    "Recreating our dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb966d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:25.480961Z",
     "iopub.status.busy": "2021-12-01T17:19:25.480863Z",
     "iopub.status.idle": "2021-12-01T17:19:25.661239Z",
     "shell.execute_reply": "2021-12-01T17:19:25.661070Z",
     "shell.execute_reply.started": "2021-12-01T17:19:25.480905Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_valid = loaded_lens.transform(loaded_valid_df)\n",
    "y_valid = loaded_valid_df['discharged_in_48hr'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0bb5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:25.661511Z",
     "iopub.status.busy": "2021-12-01T17:19:25.661416Z",
     "iopub.status.idle": "2021-12-01T17:19:25.663509Z",
     "shell.execute_reply": "2021-12-01T17:19:25.663397Z",
     "shell.execute_reply.started": "2021-12-01T17:19:25.661456Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# then we have already loaded in our model in the previous section\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7604972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T17:19:25.663785Z",
     "iopub.status.busy": "2021-12-01T17:19:25.663679Z",
     "iopub.status.idle": "2021-12-01T17:19:26.413611Z",
     "shell.execute_reply": "2021-12-01T17:19:26.413454Z",
     "shell.execute_reply.started": "2021-12-01T17:19:25.663712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id=best_run_id):\n",
    "    \n",
    "    mlflow_log_tag_dict(tag_dict, 'tag_dict.yaml')\n",
    "    \n",
    "    # create a 2-column dataframe of the predicted probabilities and true label,\n",
    "    # for each patient in the validation set\n",
    "    eval_df = pd.DataFrame({\n",
    "                'predict_proba':model.predict_proba(X_valid.values)[:,1], \n",
    "                'label':y_valid.to_numpy().ravel()\n",
    "               }, \n",
    "        columns=['predict_proba','label'],\n",
    "        index=X_valid.index)   \n",
    "    eval_df['horizon_dt'] = loaded_valid_df.set_index('episode_slice_id')['horizon_dt']\n",
    "    \n",
    "    # write eval_df to csv and log in MLFlow\n",
    "    eval_path = tmp_path / 'eval.csv'\n",
    "    eval_df.to_csv(eval_path)\n",
    "    mlflow.log_artifact(eval_path)\n",
    "    \n",
    "    \n",
    "    # use eval_df to store a new metric\n",
    "    eval_log_loss = log_loss(eval_df['label'],eval_df['predict_proba'])\n",
    "    mlflow.log_metric('log_loss', eval_log_loss)\n",
    "    \n",
    "    \n",
    "    # save a new figure alongside our registered model\n",
    "    eval_confusion = confusion_matrix(m.predict(X_valid.values), y_valid.to_numpy())\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=eval_confusion,\n",
    "                              display_labels=['discharged','remained_after_48hrs'])\n",
    "    \n",
    "    confusion_path = tmp_path / 'confusion_fig_2.png'\n",
    "    disp.plot(cmap=plt.cm.Blues).figure_.savefig(confusion_path)\n",
    "    mlflow.log_artifact(confusion_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270ae35-e925-49ee-b12d-f8e0c76c3d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
